import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from tqdm import tqdm

URL = "http://service.jct.org.tw/tjcha_cert/ema.aspx"

def get_tokens(session):
    """å–å¾—ç•¶å‰è¡¨å–®çš„ ASP.NET hidden æ¬„ä½å€¼"""
    resp = session.get(URL)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, 'html.parser')
    return {
        '__VIEWSTATE': soup.find('input', id='__VIEWSTATE')['value'],
        '__VIEWSTATEGENERATOR': soup.find('input', id='__VIEWSTATEGENERATOR')['value'],
        '__EVENTVALIDATION': soup.find('input', id='__EVENTVALIDATION')['value']
    }

def scrape_all():
    session = requests.Session()
    records = []

    # é¦–æ¬¡æŠ“ä¸‹ä¾†æ‰€æœ‰ç¸£å¸‚èˆ‡ç´šåˆ¥
    tokens = get_tokens(session)
    soup = BeautifulSoup(session.get(URL).text, 'html.parser')
    counties = [opt['value'] for opt in soup.select('#DropDownList1 option')]
    levels = [opt['value'] for opt in soup.select('#DropDownList2 option')]

    total = len(counties) * len(levels)
    pbar = tqdm(total=total, desc="æŸ¥è©¢é€²åº¦")

    for county in counties:
        for level in levels:
            tokens = get_tokens(session)  # é‡æ–°å–å¾— hidden æ¬„ä½
            form = {
                '__VIEWSTATE': tokens['__VIEWSTATE'],
                '__VIEWSTATEGENERATOR': tokens['__VIEWSTATEGENERATOR'],
                '__EVENTVALIDATION': tokens['__EVENTVALIDATION'],
                '__EVENTTARGET': '',
                '__EVENTARGUMENT': '',
                'DropDownList1': county,
                'DropDownList2': level,
                'Button1': 'æŸ¥è©¢'
            }
            try:
                resp = session.post(URL, data=form)
                resp.raise_for_status()
            except Exception as e:
                print(f"ðŸ”´ æäº¤å¤±æ•—: {county}, {level} -> {e}")
                pbar.update(1)
                time.sleep(1.0)
                continue

            soup = BeautifulSoup(resp.text, 'html.parser')
            table = soup.find('table', id='GridView1')
            if table:
                rows = table.find_all('tr')
                # headers = [th.text.strip() for th in rows[0].find_all('th')]
                for row in rows[1:]:
                    cols = row.find_all('td')
                    if len(cols) < 8:
                        continue
                    records.append({
                        'åºè™Ÿ': cols[0].get_text(strip=True),
                        'é†«ç™‚æ©Ÿæ§‹ä»£ç¢¼': cols[1].get_text(strip=True),
                        'æ©Ÿæ§‹åç¨±': cols[2].get_text(strip=True),
                        'ç¸£å¸‚åˆ¥': cols[3].get_text(strip=True),
                        'è©•å®šç­‰ç´š': cols[4].get_text(strip=True),
                        'æ•ˆæœŸ': cols[5].get_text(strip=True),
                        'æ©Ÿæ§‹é›»è©±': cols[6].get_text(strip=True),
                        'æ©Ÿæ§‹åœ°å€': cols[7].get_text(strip=True).replace('\xa0', '').strip()
                    })
            # è‹¥æ²’æœ‰ tableï¼Œè¡¨ç¤ºè©²çµ„åˆç„¡è³‡æ–™ï¼Œç•¥éŽ
            pbar.update(1)
            time.sleep(1.0)
    pbar.close()

    # æ•´ç† DataFrameã€åŽ»é‡ã€é‡æ–°æ¨™è¨»åºè™Ÿ
    df = pd.DataFrame(records)
    if not df.empty:
        df = df.drop_duplicates(subset=['é†«ç™‚æ©Ÿæ§‹ä»£ç¢¼']).reset_index(drop=True)
        df['åºè™Ÿ'] = df.index + 1
    return df

if __name__ == "__main__":
    df = scrape_all()
    if df is not None:
        print(f"âœ… å…±å–å¾— {len(df)} ç­†ç¨ç«‹è³‡æ–™")
        print(df.head(10))
        df.to_csv('jct_ema_data.csv', index=False, encoding='utf-8-sig')
        print("âœ… å·²å„²å­˜è‡³ jct_ema_data.csv")
